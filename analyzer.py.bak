import docker
import requests
import logging
import os
import json
from datetime import datetime, timedelta

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# --- Configuration ---
OLLAMA_API_URL = os.environ.get("OLLAMA_API_URL", "http://host.docker.internal:11434/api/generate")
OLLAMA_MODEL = os.environ.get("OLLAMA_MODEL", "phi3") # Use a smaller, faster model if possible
LOG_LINES_TO_FETCH = int(os.environ.get("LOG_LINES_TO_FETCH", "200")) # Number of recent lines per container
DOCKER_SOCKET_PATH = "/var/run/docker.sock" # Standard path inside container when mounted

# Stores the last check time for each container to avoid re-analyzing old logs (optional improvement)
# For simplicity in this version, we rely on LOG_LINES_TO_FETCH and database duplicate checks.

def get_docker_client():
    """Initializes and returns a Docker client."""
    try:
        # When running inside a container, use the mounted socket
        client = docker.DockerClient(base_url=f'unix://{DOCKER_SOCKET_PATH}')
        client.ping() # Test connection
        logging.info("Successfully connected to Docker daemon.")
        return client
    except Exception as e:
        logging.error(f"Error connecting to Docker daemon: {e}")
        logging.error("Ensure the Docker socket is mounted correctly into the container (-v /var/run/docker.sock:/var/run/docker.sock)")
        return None

def fetch_container_logs(container):
    """Fetches recent logs for a given container."""
    try:
        logs = container.logs(tail=LOG_LINES_TO_FETCH, stream=False, timestamps=False)
        return logs.decode('utf-8', errors='replace') # Decode bytes to string
    except docker.errors.NotFound:
        logging.warning(f"Container {container.name} not found during log fetch (might have stopped).")
        return None
    except Exception as e:
        logging.error(f"Error fetching logs for container {container.name}: {e}")
        return None

def analyze_logs_with_ollama(logs):
    """Sends logs to Ollama for analysis and returns the response."""
    if not logs or logs.isspace():
        return "NORMAL" # No logs to analyze

    prompt = f"""
Analyze the following Docker container logs for potential errors, warnings, or unusual patterns.
Focus on exceptions, crashes, keywords like 'error', 'warning', 'failed', 'exception', 'critical', stack traces, or security-related messages.
Respond ONLY with the word 'NORMAL' if no significant issues are found.
If abnormalities ARE found, provide a SHORT (1-2 sentences) description of the potential issue and quote the MOST RELEVANT log line(s) directly after your description, prefixed with 'Relevant Log(s):'. Do not include introductory phrases like "Here is the analysis".

--- LOGS ---
{logs}
--- END LOGS ---

Analysis Result:"""

    payload = {
        "model": OLLAMA_MODEL,
        "prompt": prompt,
        "stream": False, # Get the full response at once
        "options": { # Optional: Adjust parameters if needed
             "temperature": 0.2 # Lower temperature for more deterministic output
        }
    }
    try:
        response = requests.post(OLLAMA_API_URL, json=payload, timeout=120) # Generous timeout
        response.raise_for_status() # Raise HTTPError for bad responses (4xx or 5xx)

        result = response.json()
        analysis_text = result.get('response', '').strip()

        logging.debug(f"Ollama Raw Response: {analysis_text}")

        # Basic check: If Ollama didn't follow instructions and just said NORMAL
        if analysis_text.upper() == "NORMAL":
             return "NORMAL"
        # More robust check: If it *contains* normal but maybe other text
        elif "NORMAL" in analysis_text.upper() and len(analysis_text) < 20:
             return "NORMAL"
        # Check if it seems like an abnormality report
        elif "Relevant Log(s):" in analysis_text or any(keyword in analysis_text.lower() for keyword in ['error', 'warning', 'failed', 'exception', 'critical', 'unusual']):
            return analysis_text # Return the detected abnormality description
        else:
             # If Ollama returns something unexpected, assume it's not an error for now, log it
             logging.warning(f"Ollama returned unexpected format: {analysis_text}")
             return "NORMAL"


    except requests.exceptions.RequestException as e:
        logging.error(f"Error communicating with Ollama API at {OLLAMA_API_URL}: {e}")
        return f"ERROR: Could not contact Ollama - {e}"
    except Exception as e:
        logging.error(f"Error during Ollama analysis: {e}")
        return f"ERROR: Analysis failed - {e}"


def extract_log_snippet(analysis_result, full_logs):
    """Extracts the relevant log snippet mentioned by Ollama or a default snippet."""
    prefix = "Relevant Log(s):"
    if prefix in analysis_result:
        try:
            # Take the text after the prefix
            snippet = analysis_result.split(prefix, 1)[1].strip()
            # Limit snippet length
            return snippet[:500] # Limit to 500 chars
        except Exception:
            pass # Fallback if splitting fails

    # Fallback: Try to find keywords in the original logs if Ollama didn't provide a snippet
    keywords = ['error', 'warning', 'failed', 'exception', 'critical']
    log_lines = full_logs.strip().split('\n')
    for line in reversed(log_lines): # Check recent lines first
        if any(keyword in line.lower() for keyword in keywords):
            return line[:500] # Return the first relevant line found

    # Ultimate fallback: return last non-empty line
    for line in reversed(log_lines):
        if line.strip():
            return line.strip()[:500]

    return "(No specific log line identified)" # Default if no suitable snippet found
